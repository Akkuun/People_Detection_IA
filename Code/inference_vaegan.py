"""
VAE-GAN Inference
Applique le style ONOT aux images CelebA captur√©es en utilisant VAE-GAN
"""

import os
import cv2
import numpy as np
import torch
import torchvision.transforms as T
from PIL import Image
from pathlib import Path

class VAEGANInference:
    """Classe pour appliquer le style transfer VAE-GAN"""
    
    def __init__(self, checkpoint_path=None, device=None, image_size=128):
        """
        Initialiser le mod√®le VAE-GAN
        
        Args:
            checkpoint_path: Chemin vers le checkpoint du mod√®le entra√Æn√© (optionnel, cherche automatiquement)
            device: GPU ou CPU
            image_size: Taille des images (128)
        """
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = device
        
        self.checkpoint_path = checkpoint_path
        self.image_size = image_size
        self.encoder = None  # Encodeur VAE
        self.decoder = None  # D√©codeur VAE
        self.transform = T.Compose([
            T.Resize((image_size, image_size)),
            T.ToTensor(),
            T.Normalize([0.5]*3, [0.5]*3)
        ])
        
        # Charger le mod√®le : d'abord le checkpoint fourni, sinon chercher le checkpoint
        if checkpoint_path and os.path.exists(checkpoint_path):
            self._load_checkpoint(checkpoint_path)
        else:
            # Chercher le checkpoint disponible
            if not self.find_latest_checkpoint('checkpoints_vaegan'):
                print(f"‚ö†Ô∏è  Aucun checkpoint VAE-GAN trouv√©. Entra√Ænez le mod√®le avec: python3 train.py")
    
    def _load_checkpoint(self, checkpoint_path):
        """Charger l'encodeur et d√©codeur depuis un checkpoint"""
        try:
            from vae_generator import VAEGenerator
            
            # Charger le checkpoint
            try:
                checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)
            except TypeError:
                # Fallback pour les versions anciennes de torch
                checkpoint = torch.load(checkpoint_path, map_location=self.device)
            
            # Initialiser le VAE-GAN
            self.vae_generator = VAEGenerator().to(self.device)
            
            # Charger les poids - supporter plusieurs formats
            loaded = False
            
            # Format 1: 'G' (depuis trainVAEGAN.py avec ema_G pour inf√©rence)
            if 'G' in checkpoint:
                self.vae_generator.load_state_dict(checkpoint['G'])
                loaded = True
                print(f"‚úÖ Poids G charg√©s depuis checkpoint")
            
            # Format 2: 'ema_G' (EMA weights for better quality)
            elif 'ema_G' in checkpoint:
                self.vae_generator.load_state_dict(checkpoint['ema_G'])
                loaded = True
                print(f"‚úÖ Poids ema_G charg√©s depuis checkpoint (meilleure qualit√©)")
            
            # Format 3: 'generator' (ancien format)
            elif 'generator' in checkpoint:
                self.vae_generator.load_state_dict(checkpoint['generator'])
                loaded = True
                print(f"‚úÖ Poids generator charg√©s depuis checkpoint")
            
            if not loaded:
                print(f"‚ö†Ô∏è  Format de checkpoint non reconnu. Cl√©s disponibles: {list(checkpoint.keys())}")
                self.vae_generator = None
                return
            
            self.vae_generator.eval()
            
            epoch = checkpoint.get('epoch', 'unknown')
            print(f"‚úÖ Mod√®le VAE-GAN charg√© depuis {checkpoint_path} (Epoch {epoch})")
            
        except Exception as e:
            print(f"‚ùå Erreur chargement checkpoint VAE-GAN: {e}")
            import traceback
            traceback.print_exc()
            self.vae_generator = None
    
    def find_latest_checkpoint(self, checkpoint_dir='checkpoints_vaegan'):
        """Chercher et charger le checkpoint VAE-GAN (pr√©f√®re best si disponible)"""
        checkpoint_dir_path = Path(checkpoint_dir)
        
        # Chercher dans le r√©pertoire courant et le r√©pertoire Code
        possible_dirs = [
            checkpoint_dir_path,
            Path('/home/paradox/Bureau/M2/ProjetImage/Code') / checkpoint_dir,
            Path.cwd() / checkpoint_dir
        ]
        
        for ckpt_dir in possible_dirs:
            if not ckpt_dir.exists():
                continue
            
            # Pr√©f√©rer le meilleur checkpoint
            best_checkpoint_path = ckpt_dir / 'best_vaegan_model.pth'
            if best_checkpoint_path.exists():
                print(f"üìÇ Meilleur checkpoint VAE-GAN trouv√©: {best_checkpoint_path}")
                self._load_checkpoint(str(best_checkpoint_path))
                return self.vae_generator is not None
            
            # Fallback sur le checkpoint courant
            checkpoint_path = ckpt_dir / 'vaegan_model.pth'
            if checkpoint_path.exists():
                print(f"üìÇ Checkpoint VAE-GAN trouv√©: {checkpoint_path}")
                self._load_checkpoint(str(checkpoint_path))
                return self.vae_generator is not None
        
        print(f"‚ùå Aucun checkpoint VAE-GAN trouv√©: checkpoints_vaegan/vaegan_model.pth")
        print(f"   Entra√Ænez d'abord le mod√®le avec: python3 trainVAEGAN.py")
        return False
    
    @property
    def G(self):
        """Propri√©t√© pour compatibilit√© avec le code existant"""
        return self.vae_generator
    
    def apply_style(self, image, return_original=False):
        """
        Appliquer le style transfer VAE-GAN √† une image
        
        Args:
            image: Image numpy (BGR) ou chemin vers l'image
            return_original: Si True, retourne aussi l'original
        
        Returns:
            Image stylis√©e (numpy, BGR) ou tuple (original, stylis√©) si return_original=True
        """
        if self.vae_generator is None:
            print("‚ùå Mod√®le VAE-GAN non charg√©")
            return None
        
        try:
            # Charger l'image si c'est un chemin
            if isinstance(image, str):
                img = cv2.imread(image)
                if img is None:
                    print(f"‚ùå Impossible de charger {image}")
                    return None
            else:
                img = image.copy()
            
            original_size = img.shape[:2]
            
            # Redimensionner
            img_resized = cv2.resize(img, (self.image_size, self.image_size))
            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
            
            # Convertir en tensor
            img_pil = Image.fromarray(img_rgb.astype('uint8'))
            img_tensor = self.transform(img_pil).unsqueeze(0).to(self.device)
            
            # Inf√©rence avec VAE-GAN
            with torch.no_grad():
                output = self.vae_generator(img_tensor)
            
            # G√©rer le cas o√π le mod√®le retourne un tuple (mu, logvar, reconstruction)
            if isinstance(output, tuple):
                fake_B = output[0]  # Prendre la reconstruction (premier √©l√©ment)
            else:
                fake_B = output
            
            # D√©normaliser et convertir en numpy
            fake_B = fake_B.squeeze(0).cpu()
            fake_B = (fake_B * 0.5 + 0.5).clamp(0, 1)
            fake_B_np = (fake_B.permute(1, 2, 0).numpy() * 255).astype(np.uint8)
            
            # Convertir RGB -> BGR
            fake_B_bgr = cv2.cvtColor(fake_B_np, cv2.COLOR_RGB2BGR)
            
            # Redimensionner √† la taille originale
            result = cv2.resize(fake_B_bgr, (original_size[1], original_size[0]))
            
            if return_original:
                return img, result
            return result
        
        except Exception as e:
            print(f"‚ùå Erreur lors du style transfer VAE-GAN: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def apply_style_batch(self, image_list):
        """
        Appliquer le style √† plusieurs images
        
        Args:
            image_list: Liste d'images ou de chemins
        
        Returns:
            Liste d'images stylis√©es
        """
        results = []
        for img in image_list:
            styled = self.apply_style(img)
            if styled is not None:
                results.append(styled)
        return results


# Fonction de d√©monstration
def demo():
    """D√©monstration du VAE-GAN inference"""
    
    inference = VAEGANInference(image_size=128)
    
    # Essayer de charger le checkpoint
    if inference.G is None:
        print("‚ùå Pas de mod√®le VAE-GAN entra√Æn√©. Entra√Ænez d'abord avec: python3 train.py")
        return
    
    # Tester sur quelques images CelebA
    celeba_dir = '/home/paradox/Bureau/M2/ProjetImage/dataset/CelebA'
    test_images = list(Path(celeba_dir).glob('**/*.jpg'))[:5]
    
    os.makedirs('styled_outputs', exist_ok=True)
    
    print(f"\nüé® Stylisation VAE-GAN de {len(test_images)} images...")
    for img_path in test_images:
        print(f"Traitement {img_path.name}...")
        
        # Appliquer le style
        original, styled = inference.apply_style(str(img_path), return_original=True)
        
        if styled is not None:
            # Combiner original et stylis√©
            combined = np.hstack([original, styled])
            
            # Sauvegarder
            output_path = f'styled_outputs/{img_path.stem}_vaegan_stylized.jpg'
            cv2.imwrite(output_path, combined)
            print(f"‚úÖ Sauvegard√©: {output_path}")


if __name__ == '__main__':
    demo()
