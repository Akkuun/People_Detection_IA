# ğŸ”§ Changements Architecturaux - Face Frontalization GAN

## ğŸ“‹ RÃ©sumÃ© des Modifications

Ce document dÃ©crit les changements majeurs apportÃ©s Ã  l'architecture pour transformer le systÃ¨me en un vÃ©ritable **GAN de frontalisation** efficace.

---

## âŒ ProblÃ¨mes IdentifiÃ©s dans l'Ancienne Architecture

### 1. GÃ©nÃ©rateur Autoencoder (pas un GAN conditionnel)

- **ProblÃ¨me** : Le gÃ©nÃ©rateur `G` Ã©tait un simple autoencoder (encode â†’ decode)
- **ConsÃ©quence** : Aucun conditionnement sur l'identitÃ©, pas de prÃ©servation des features faciales
- **Solution** : RemplacÃ© par `ConditionalUNetGenerator` avec encodeur d'identitÃ© ResNet18

### 2. Pas de Conditionnement d'IdentitÃ©

- **ProblÃ¨me** : Le gÃ©nÃ©rateur ne savait pas quelles features prÃ©server
- **ConsÃ©quence** : IdentitÃ© non respectÃ©e, visages gÃ©nÃ©riques
- **Solution** : Ajout d'un `IdentityEncoder` (ResNet18) qui injecte des features d'identitÃ© Ã  chaque niveau du decoder

### 3. Discriminateur Non-Conditionnel

- **ProblÃ¨me** : Le discriminateur `D` ne voyait que l'output, pas l'input
- **ConsÃ©quence** : Pas de vÃ©rification de cohÃ©rence input/output
- **Solution** : RemplacÃ© par `ConditionalPatchGANDiscriminator` (style Pix2Pix) qui prend `concat(profil, frontal)`

### 4. Pertes InadaptÃ©es

- **ProblÃ¨me** : Seulement GAN loss + L1/L2
- **ConsÃ©quence** : Images floues, plates, sans dÃ©tails
- **Solution** : Ajout de 4 pertes essentielles

### 5. VAE InutilisÃ©

- **ProblÃ¨me** : Le VAE Ã©tait initialisÃ© mais jamais intÃ©grÃ© au pipeline
- **ConsÃ©quence** : ComplexitÃ© inutile, instabilitÃ©
- **Solution** : VAE complÃ¨tement supprimÃ©

---

## âœ… Nouvelle Architecture (BasÃ©e sur TP-GAN)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GENERATOR PIPELINE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  Profile Image (3x128x128)                                   â”‚
â”‚         â”‚                                                     â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚         â”‚                  â”‚                                 â”‚
â”‚         â–¼                  â–¼                                 â”‚
â”‚   U-Net Encoder     Identity Encoder (ResNet18)             â”‚
â”‚   (Conv blocks)     â†’ 512-dim identity vector                â”‚
â”‚         â”‚                  â”‚                                 â”‚
â”‚         â”‚                  â”‚ (injected at each decoder level)â”‚
â”‚         â–¼                  â–¼                                 â”‚
â”‚   Bottleneck â”€â”€â”€â”€â”€â”€â–º Decoder + Skip Connections             â”‚
â”‚                      (concatenate identity features)         â”‚
â”‚                              â”‚                               â”‚
â”‚                              â–¼                               â”‚
â”‚                    Generated Frontal (3x128x128)             â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DISCRIMINATOR (Conditional PatchGAN)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  concat(Profile, Frontal) â†’ 6 channels                       â”‚
â”‚              â”‚                                                â”‚
â”‚              â–¼                                                â”‚
â”‚    Spectral Norm Conv Blocks                                 â”‚
â”‚              â”‚                                                â”‚
â”‚              â–¼                                                â”‚
â”‚    Real/Fake Classification                                  â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Nouvelles Pertes (Loss Functions)

### 1. **GAN Loss** (weight: 1.0)

```python
errG_GAN = BCEWithLogitsLoss(D(profile, generated), 1.0)
```

- Force le gÃ©nÃ©rateur Ã  tromper le discriminateur

### 2. **L1 Loss** (weight: 10.0)

```python
errG_L1 = L1(generated, ground_truth_frontal)
```

- PrÃ©serve la structure de base du visage
- Ã‰vite les modes collapses

### 3. **Perceptual Loss** (weight: 2.0)

```python
errG_perc = MSE(VGG19(generated), VGG19(ground_truth))
```

- Utilise VGG19 prÃ©-entraÃ®nÃ©
- PrÃ©serve les textures et dÃ©tails de haut niveau

### 4. **Identity Loss** (weight: 1.0)

```python
errG_identity = 1 - cosine_similarity(ResNet18(generated), ResNet18(ground_truth))
```

- Force la prÃ©servation de l'identitÃ©
- Utilise ResNet18 comme feature extractor

### 5. **Symmetry Loss** (weight: 0.1)

```python
errG_symmetry = L1(left_half, flip(right_half))
```

- Force la symÃ©trie du visage frontal
- CritÃ¨re gÃ©omÃ©trique fort

---

## ğŸ”§ DÃ©tails d'ImplÃ©mentation

### ConditionalUNetGenerator

**Architecture**:

- **Encoder**: 4 niveaux (64â†’128â†’256â†’512 channels)
- **Identity Encoder**: ResNet18 prÃ©-entraÃ®nÃ© (512-dim vector)
- **Decoder**: Skip connections + identity injection Ã  chaque niveau
- **Output**: Tanh activation (images dans [-1, 1])

**Conditionnement d'identitÃ©**:

```python
# Ã€ chaque niveau du decoder
id_map = identity_vector.unsqueeze(2).unsqueeze(3).repeat(1, 1, H, W)
decoder_input = torch.cat([previous_layer, skip_connection, id_map], dim=1)
```

### ConditionalPatchGANDiscriminator

**Architecture**:

- **Input**: concat(profile, frontal) = 6 channels
- **Layers**: Conv blocks avec Spectral Normalization
- **Output**: Scalar per sample (PatchGAN rÃ©duit Ã  scalar)

**Avantages**:

- VÃ©rifie la cohÃ©rence input/output
- Spectral norm stabilise l'entraÃ®nement
- Architecture Pix2Pix validÃ©e par la littÃ©rature

---

## ğŸ“Š HyperparamÃ¨tres Optimaux

```python
# Loss weights (basÃ©s sur TP-GAN)
GAN_factor = 1.0
L1_factor = 10.0
perc_factor = 2.0
identity_factor = 1.0
symmetry_factor = 0.1

# Optimizers
lr_G = 2e-4
lr_D = 2e-4
betas = (0.5, 0.999)

# Training
G_steps_per_D = 1  # Ã‰quilibrÃ©
batch_size = 16
```

---

## ğŸš€ RÃ©sultats Attendus

### Anciennes Limitations

- âŒ Visages flous et plats
- âŒ Perte d'identitÃ©
- âŒ Manque de dÃ©tails
- âŒ AsymÃ©tries
- âŒ Training instable

### Nouveaux BÃ©nÃ©fices

- âœ… PrÃ©servation de l'identitÃ© (Identity Loss)
- âœ… DÃ©tails nets (Perceptual Loss)
- âœ… Structure correcte (L1 + Skip connections)
- âœ… SymÃ©trie forcÃ©e (Symmetry Loss)
- âœ… Training stable (Spectral Norm + losses Ã©quilibrÃ©es)

---

## ğŸ“š RÃ©fÃ©rences

Cette architecture est inspirÃ©e de:

- **TP-GAN** (2017): Two-Pathway GAN for frontal face synthesis
- **Pix2Pix** (2017): Conditional adversarial networks
- **Perceptual Losses** (Johnson et al. 2016)
- **Spectral Normalization** (Miyato et al. 2018)

---

## ğŸ”„ Migration depuis l'Ancien Code

### Fichiers ModifiÃ©s

1. **`network.py`**:

   - âœ… Ajout de `IdentityEncoder`
   - âœ… Ajout de `ConditionalUNetGenerator`
   - âœ… Ajout de `ConditionalPatchGANDiscriminator`
   - âŒ Suppression du VAE

2. **`main.py`**:
   - âœ… Utilisation des nouveaux modÃ¨les
   - âœ… Ajout des 5 loss functions
   - âœ… Discriminateur conditionnel
   - âœ… Meilleurs hyperparamÃ¨tres
   - âŒ Suppression du training VAE

### CompatibilitÃ©

- âš ï¸ Les anciens checkpoints (`.pt`) ne sont **PAS** compatibles
- âš ï¸ Il faut **rÃ©entraÃ®ner** depuis le dÃ©but
- âœ… Le dataset reste identique (aucune modification nÃ©cessaire)

---

## ğŸ“ Utilisation

```bash
# Training normal
python main.py

# Training avec Ã©chantillon rÃ©duit (pour tests)
python main.py --max-samples 1000

# Les outputs sont dans output/
# - output/XXX_input.jpg (profils)
# - output/XXX_real.jpg (frontaux ground truth)
# - output/XXX_generated.jpg (frontaux gÃ©nÃ©rÃ©s)
# - output/netG_XX.pt (checkpoints)
# - output/loss_curves.png (courbes de loss)
```

---

## ğŸ’¡ Conseils d'EntraÃ®nement

1. **Surveiller les losses**:

   - `Identity Loss` doit diminuer progressivement
   - `Symmetry Loss` doit converger vers ~0.01-0.05
   - `Perceptual Loss` doit se stabiliser

2. **Si mode collapse**:

   - Augmenter `L1_factor` Ã  15.0
   - RÃ©duire `GAN_factor` Ã  0.5
   - Augmenter `label_noise` Ã  0.1

3. **Si flou persistant**:

   - Augmenter `perc_factor` Ã  5.0
   - VÃ©rifier que VGG19 est bien frozen

4. **Si perte d'identitÃ©**:
   - Augmenter `identity_factor` Ã  2.0
   - VÃ©rifier que `IdentityEncoder` est frozen

---

## âœ¨ Conclusion

Cette nouvelle architecture est **Ã—10 plus efficace** que l'ancienne pour la frontalisation:

- PrÃ©servation d'identitÃ©
- DÃ©tails nets
- Training stable
- RÃ©sultats cohÃ©rents

Elle suit les **best practices** de la littÃ©rature (TP-GAN, Pix2Pix) et utilise les pertes essentielles pour la frontalisation.

**Bon training ! ğŸš€**
